{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse Llama models to study wavelet-like structure in attenion heads due to positional encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import math\n",
    "from datasets import load_dataset\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoPEAnalyzer:\n",
    "    def __init__(self, model_name: str = \"meta-llama/Llama-3.2-1B\"):\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.logger.info(f\"Using device: {self.device}\")\n",
    "\n",
    "        self.logger.info(f\"Loading model {model_name}...\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            low_cpu_mem_usage=True,\n",
    "            attn_implementation=\"eager\",\n",
    "        ).to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model.eval()\n",
    "\n",
    "        # Extract and store model dimensions\n",
    "        self.hidden_size = self.model.config.hidden_size\n",
    "        self.num_heads = self.model.config.num_attention_heads\n",
    "        self.head_dim = self.hidden_size // self.num_heads\n",
    "        self.num_layers = self.model.config.num_hidden_layers\n",
    "\n",
    "        self.logger.info(\n",
    "            f\"Model loaded: {self.num_layers} layers, {self.num_heads} heads\"\n",
    "        )\n",
    "\n",
    "    def analyze_dataset(self, num_samples: int = 500) -> List[Dict]:\n",
    "        \"\"\"Analyze multiple samples from the dataset with progress tracking.\"\"\"\n",
    "        self.logger.info(f\"Starting analysis of {num_samples} samples...\")\n",
    "\n",
    "        dataset = load_dataset(\"bookcorpus\", split=\"train\", streaming=True)\n",
    "        texts = []\n",
    "\n",
    "        with tqdm(desc=\"Collecting samples\") as pbar:\n",
    "            for item in dataset:\n",
    "                text = item[\"text\"]\n",
    "                if 10 <= len(text.split()) <= 100:\n",
    "                    texts.append(text)\n",
    "                    pbar.update(1)\n",
    "                    if len(texts) == num_samples:\n",
    "                        break\n",
    "\n",
    "        self.logger.info(f\"Collected {len(texts)} suitable text samples\")\n",
    "\n",
    "        results = []\n",
    "        with tqdm(total=len(texts), desc=\"Analyzing samples\") as pbar:\n",
    "            for idx, text in enumerate(texts):\n",
    "                try:\n",
    "                    result = self.analyze_single_text(text)\n",
    "                    if result is not None:\n",
    "                        results.append(result)\n",
    "\n",
    "                    if (idx + 1) % 50 == 0:\n",
    "                        if torch.cuda.is_available():\n",
    "                            torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error processing sample {idx}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def analyze_single_text(self, text: str) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Analyze attention patterns for a single text input across all layers.\n",
    "        Returns metrics for each layer and attention head.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Tokenize and prepare input\n",
    "            tokens = self.tokenizer(\n",
    "                text, return_tensors=\"pt\", truncation=True, max_length=512\n",
    "            ).to(self.device)\n",
    "            batch_size, seq_len = tokens.input_ids.shape\n",
    "\n",
    "            # Get attention patterns for all layers\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**tokens, output_attentions=True)\n",
    "                all_layer_attentions = (\n",
    "                    outputs.attentions\n",
    "                )\n",
    "\n",
    "            # Analyze patterns for each layer\n",
    "            results = {}\n",
    "            for layer_idx, layer_attention in enumerate(all_layer_attentions):\n",
    "                layer_results = {}\n",
    "                layer_attention = layer_attention[0]  \n",
    "\n",
    "                for head_idx in range(self.num_heads):\n",
    "                    head_patterns = layer_attention[head_idx]\n",
    "                    metrics = self._compute_attention_metrics(head_patterns)\n",
    "                    layer_results[f\"head_{head_idx}\"] = metrics\n",
    "\n",
    "                results[f\"layer_{layer_idx}\"] = layer_results\n",
    "\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error analyzing text: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _fit_exponential_decay(self, distance_profile: List[float]) -> float:\n",
    "        distances = np.arange(len(distance_profile))\n",
    "\n",
    "        def exp_func(x, A, c):\n",
    "            return A * np.exp(-c * x)\n",
    "\n",
    "        try:\n",
    "            # Initial guess: A=distance_profile[0], c = 0.1\n",
    "            popt, _ = curve_fit(\n",
    "                exp_func, distances, distance_profile, p0=(distance_profile[0], 0.1)\n",
    "            )\n",
    "            return float(popt[1])  # c: decay coefficient\n",
    "        except:\n",
    "            return 0.0\n",
    "\n",
    "    def _compute_attention_metrics(self, attention_weights: torch.Tensor) -> Dict:\n",
    "        \"\"\"Compute comprehensive metrics for attention patterns.\"\"\"\n",
    "        try:\n",
    "            # Handle dimensions\n",
    "            weights = attention_weights.float()\n",
    "            if weights.dim() == 3:\n",
    "                weights = weights.squeeze(0)\n",
    "\n",
    "            seq_len = weights.size(-1)\n",
    "\n",
    "            # Basic attention statistics\n",
    "            mean_attention = weights.mean().item()\n",
    "            max_attention = weights.max().item()\n",
    "            local_attention = torch.diagonal(weights).mean().item()\n",
    "\n",
    "            # Distance-based analysis\n",
    "            positions = torch.arange(seq_len, device=weights.device)\n",
    "            distances = torch.abs(positions.unsqueeze(0) - positions.unsqueeze(1))\n",
    "            weighted_distances = distances.float() * weights\n",
    "            avg_distance = weighted_distances.sum() / weights.sum()\n",
    "\n",
    "            # Build distance profile\n",
    "            unique_distances = torch.unique(distances)\n",
    "            distance_profile = []\n",
    "            for d in unique_distances:\n",
    "                mask = distances == d\n",
    "                if mask.any():\n",
    "                    avg = weights[mask].mean().item()\n",
    "                    distance_profile.append(avg)\n",
    "\n",
    "            # Compute decay coefficient using exponential fit\n",
    "            decay_coefficient = 0.0\n",
    "            if len(distance_profile) >= 2:\n",
    "                decay_coefficient = self._fit_exponential_decay(distance_profile)\n",
    "\n",
    "            return {\n",
    "                \"mean_attention\": mean_attention,\n",
    "                \"max_attention\": max_attention,\n",
    "                \"local_attention\": local_attention,\n",
    "                \"avg_distance\": avg_distance.item(),\n",
    "                \"decay_rate\": decay_coefficient,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in attention metrics computation: {str(e)}\")\n",
    "            return {\n",
    "                \"mean_attention\": 0.0,\n",
    "                \"max_attention\": 0.0,\n",
    "                \"local_attention\": 0.0,\n",
    "                \"avg_distance\": 0.0,\n",
    "                \"decay_rate\": 0.0,\n",
    "            }\n",
    "\n",
    "    def phase_shift_validation(self, text: str, shift_tokens: int = 5):\n",
    "        # Original tokens\n",
    "        orig_tokens = self.tokenizer(\n",
    "            text, return_tensors=\"pt\", truncation=True, max_length=512\n",
    "        ).to(self.device)\n",
    "        # Shifted tokens: add thingd like padding or EOS\n",
    "        prepend = [self.tokenizer.eos_token_id] * shift_tokens\n",
    "        shifted_input_ids = torch.cat(\n",
    "            [\n",
    "                torch.tensor(prepend, dtype=torch.long).unsqueeze(0).to(self.device),\n",
    "                orig_tokens.input_ids,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        # Adjust attention mask if needed\n",
    "        shifted_attention_mask = torch.cat(\n",
    "            [\n",
    "                torch.ones(shift_tokens, dtype=torch.long).unsqueeze(0).to(self.device),\n",
    "                orig_tokens.attention_mask,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        shifted_tokens = {\n",
    "            \"input_ids\": shifted_input_ids,\n",
    "            \"attention_mask\": shifted_attention_mask,\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            orig_outputs = self.model(**orig_tokens, output_attentions=True)\n",
    "            shifted_outputs = self.model(**shifted_tokens, output_attentions=True)\n",
    "\n",
    "        # Compare attention patterns\n",
    "        phase_consistency = []\n",
    "        for layer_idx, (orig_attn, shifted_attn) in enumerate(\n",
    "            zip(orig_outputs.attentions, shifted_outputs.attentions)\n",
    "        ):\n",
    "            seq_len = orig_attn.shape[-1]\n",
    "            # Align the shifted attention to compare corresponding positions\n",
    "            aligned_shifted = shifted_attn[:, :, shift_tokens:, shift_tokens:]\n",
    "            corr = (\n",
    "                torch.nn.functional.cosine_similarity(\n",
    "                    orig_attn.flatten(2), aligned_shifted.flatten(2), dim=-1\n",
    "                )\n",
    "                .mean()\n",
    "                .item()\n",
    "            )\n",
    "            phase_consistency.append(corr)\n",
    "\n",
    "        return {\n",
    "            \"phase_consistency_per_layer\": phase_consistency,\n",
    "            \"mean_phase_consistency\": float(np.mean(phase_consistency)),\n",
    "        }\n",
    "\n",
    "    def position_resolution_test(self, text: str):\n",
    "        # Original\n",
    "        tokens = self.tokenizer(\n",
    "            text, return_tensors=\"pt\", truncation=True, max_length=64\n",
    "        ).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            orig_out = self.model(**tokens, output_attentions=True)\n",
    "        orig_attn = orig_out.attentions[-1][\n",
    "            0\n",
    "        ]  # last layer attention of first batch: shape [num_heads, seq_len, seq_len]\n",
    "\n",
    "        # Create a slightly perturbed sequence by swapping two middle tokens\n",
    "        seq_len = tokens.input_ids.shape[-1]\n",
    "        if seq_len < 4:\n",
    "            return None\n",
    "        pert_tokens = tokens.input_ids.clone()\n",
    "        i, j = seq_len // 4, seq_len // 4 + 1\n",
    "        pert_tokens[0, i], pert_tokens[0, j] = pert_tokens[0, j], pert_tokens[0, i]\n",
    "\n",
    "        pert_tokens_dict = {\n",
    "            \"input_ids\": pert_tokens,\n",
    "            \"attention_mask\": tokens.attention_mask,\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            pert_out = self.model(**pert_tokens_dict, output_attentions=True)\n",
    "        pert_attn = pert_out.attentions[-1][0]\n",
    "\n",
    "        diff = (orig_attn - pert_attn).abs().mean().item()\n",
    "\n",
    "        attn_flat = orig_attn.mean(0)  # average across heads\n",
    "        attn_distribution = attn_flat.mean(0)  # average attention over queries\n",
    "        attn_distribution = attn_distribution / (attn_distribution.sum() + 1e-10)\n",
    "        pos_entropy = entropy(attn_distribution.cpu().numpy())\n",
    "\n",
    "        return {\"position_sensitivity\": diff, \"positional_entropy\": float(pos_entropy)}\n",
    "\n",
    "    def visualize_results(self, results: List[Dict]):\n",
    "        \"\"\"Create comprehensive visualizations of the analysis results.\"\"\"\n",
    "        if not results:\n",
    "            self.logger.warning(\"No results to visualize.\")\n",
    "            return\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "\n",
    "        self._plot_attention_distance_heatmap(axes[0, 0], results)\n",
    "        self._plot_local_global_distribution(axes[0, 1], results)\n",
    "        self._plot_layer_evolution(axes[1, 0], results)\n",
    "        self._plot_attention_decay(axes[1, 1], results)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def _plot_attention_distance_heatmap(self, ax, results):\n",
    "        \"\"\"Plot heatmap of attention distances for all layers.\"\"\"\n",
    "        distances = np.zeros((self.num_layers, self.num_heads))\n",
    "\n",
    "        for result in results:\n",
    "            for layer_idx in range(self.num_layers):\n",
    "                layer_key = f\"layer_{layer_idx}\"\n",
    "                if layer_key in result:\n",
    "                    for head_idx in range(self.num_heads):\n",
    "                        head_key = f\"head_{head_idx}\"\n",
    "                        if head_key in result[layer_key]:\n",
    "                            distances[layer_idx, head_idx] += result[layer_key][\n",
    "                                head_key\n",
    "                            ][\"avg_distance\"]\n",
    "\n",
    "        distances /= len(results)\n",
    "\n",
    "        im = ax.imshow(distances, cmap=\"viridis\")\n",
    "        plt.colorbar(im, ax=ax)\n",
    "        ax.set_title(\"Average Attention Distance\")\n",
    "        ax.set_xlabel(\"Head\")\n",
    "        ax.set_ylabel(\"Layer\")\n",
    "\n",
    "    def _plot_local_global_distribution(self, ax, results):\n",
    "        \"\"\"Plot distribution of local vs global attention for all layers.\"\"\"\n",
    "        local_ratios = []\n",
    "        layers = []\n",
    "        heads = []\n",
    "\n",
    "        for result in results:\n",
    "            for layer_idx in range(self.num_layers):\n",
    "                layer_key = f\"layer_{layer_idx}\"\n",
    "                if layer_key in result:\n",
    "                    for head_idx in range(self.num_heads):\n",
    "                        head_key = f\"head_{head_idx}\"\n",
    "                        if head_key in result[layer_key]:\n",
    "                            data = result[layer_key][head_key]\n",
    "                            local_ratio = data[\"local_attention\"] / (\n",
    "                                data[\"mean_attention\"] + 1e-10\n",
    "                            )\n",
    "                            local_ratios.append(local_ratio)\n",
    "                            layers.append(layer_idx)\n",
    "                            heads.append(head_idx)\n",
    "\n",
    "        if local_ratios:\n",
    "            scatter = ax.scatter(\n",
    "                layers, local_ratios, c=heads, cmap=\"viridis\", alpha=0.6\n",
    "            )\n",
    "            plt.colorbar(scatter, ax=ax, label=\"Head Index\")\n",
    "            ax.set_title(\"Local vs Global Attention Distribution\")\n",
    "            ax.set_xlabel(\"Layer\")\n",
    "            ax.set_ylabel(\"Local/Global Attention Ratio\")\n",
    "\n",
    "    def _plot_layer_evolution(self, ax, results):\n",
    "        \"\"\"Plot evolution of attention patterns through all layers.\"\"\"\n",
    "        layer_means = []\n",
    "        layer_stds = []\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            layer_distances = []\n",
    "            for result in results:\n",
    "                layer_key = f\"layer_{layer_idx}\"\n",
    "                if layer_key in result:\n",
    "                    for head_key in result[layer_key]:\n",
    "                        dist = result[layer_key][head_key][\"avg_distance\"]\n",
    "                        layer_distances.append(dist)\n",
    "\n",
    "            if layer_distances:\n",
    "                layer_means.append(np.mean(layer_distances))\n",
    "                layer_stds.append(np.std(layer_distances))\n",
    "\n",
    "        if layer_means:\n",
    "            layers = range(len(layer_means))\n",
    "            ax.plot(layers, layer_means, \"b-\", label=\"Mean Distance\")\n",
    "            ax.fill_between(\n",
    "                layers,\n",
    "                np.array(layer_means) - np.array(layer_stds),\n",
    "                np.array(layer_means) + np.array(layer_stds),\n",
    "                alpha=0.3,\n",
    "            )\n",
    "            ax.set_title(\"Attention Distance Evolution\")\n",
    "            ax.set_xlabel(\"Layer\")\n",
    "            ax.set_ylabel(\"Average Distance\")\n",
    "            ax.legend()\n",
    "\n",
    "    def _plot_attention_decay(self, ax, results):\n",
    "        \"\"\"Plot attention decay patterns for all layers.\"\"\"\n",
    "        decay_rates = []\n",
    "        layers_ = []\n",
    "        heads_ = []\n",
    "\n",
    "        for result in results:\n",
    "            for layer_idx in range(self.num_layers):\n",
    "                layer_key = f\"layer_{layer_idx}\"\n",
    "                if layer_key in result:\n",
    "                    for head_key, head_data in result[layer_key].items():\n",
    "                        head_idx = int(head_key.split(\"_\")[1])\n",
    "                        decay_rates.append(head_data[\"decay_rate\"])\n",
    "                        layers_.append(layer_idx)\n",
    "                        heads_.append(head_idx)\n",
    "\n",
    "        if decay_rates:\n",
    "            scatter = ax.scatter(\n",
    "                layers_, decay_rates, c=heads_, cmap=\"viridis\", alpha=0.6\n",
    "            )\n",
    "            plt.colorbar(scatter, ax=ax, label=\"Head Index\")\n",
    "            ax.set_title(\"Attention Decay Patterns\")\n",
    "            ax.set_xlabel(\"Layer\")\n",
    "            ax.set_ylabel(\"Decay Rate\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run comprehensive analysis pipeline.\"\"\"\n",
    "    analyzer = RoPEAnalyzer()\n",
    "    results = analyzer.analyze_dataset(num_samples=500)\n",
    "\n",
    "    fig = analyzer.visualize_results(results)\n",
    "    if fig is not None:\n",
    "        plt.show()\n",
    "\n",
    "    torch.save(results, \"rope_analysis_results.pt\")\n",
    "    print(\"\\nAnalysis complete. Results saved to 'rope_analysis_results.pt'\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencyAnalyzer:\n",
    "    \"\"\"\n",
    "    A comprehensive analyzer for studying RoPE attention patterns in the frequency domain.\n",
    "    Handles frequency analysis, interference detection, and visualization of results.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"meta-llama/Llama-3.2-1B\"):\n",
    "        \"\"\"Initialize analyzer with model and logging setup.\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.info(\"Initializing FrequencyAnalyzer...\")\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.logger.info(f\"Using device: {self.device}\")\n",
    "\n",
    "        # tokenizer with padding \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            low_cpu_mem_usage=True,\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        self.num_heads = self.model.config.num_attention_heads\n",
    "        self.num_layers = self.model.config.num_hidden_layers\n",
    "\n",
    "        self.logger.info(\n",
    "            f\"Model loaded: {self.num_layers} layers, {self.num_heads} heads\"\n",
    "        )\n",
    "\n",
    "    def analyze_frequency_bands(self, attention_patterns: torch.Tensor) -> Dict:\n",
    "        \"\"\"Analyze frequency components of attention patterns.\"\"\"\n",
    "        spectral_results = {}\n",
    "        patterns = attention_patterns.cpu().numpy()\n",
    "\n",
    "        if len(patterns.shape) != 3:\n",
    "            return {}\n",
    "\n",
    "        num_heads, seq_len, _ = patterns.shape\n",
    "        window = signal.windows.hann(seq_len)\n",
    "\n",
    "        for head_idx in range(num_heads):\n",
    "            try:\n",
    "                # Average across rows and apply window\n",
    "                head_pattern = patterns[head_idx].mean(axis=0) * window\n",
    "\n",
    "                # Compute FFT with padding\n",
    "                n_fft = 2 ** np.ceil(np.log2(seq_len)).astype(int)\n",
    "                padded_pattern = np.pad(head_pattern, (0, n_fft - seq_len))\n",
    "\n",
    "                # Compute normalized FFT and power spectrum\n",
    "                fft_vals = np.abs(fft(padded_pattern)[: n_fft // 2])\n",
    "                freq_scale = np.linspace(0, 1, n_fft // 2)\n",
    "                psd = (fft_vals**2) / (n_fft * np.sum(window**2))\n",
    "                total_power = np.sum(psd) + 1e-10\n",
    "\n",
    "                # Calculate bands\n",
    "                low_idx = max(1, int(0.25 * len(freq_scale)))\n",
    "                mid_idx = max(low_idx + 1, int(0.75 * len(freq_scale)))\n",
    "\n",
    "                spectral_results[f\"head_{head_idx}\"] = {\n",
    "                    \"band_powers\": {\n",
    "                        \"low_band\": float(np.sum(psd[:low_idx]) / total_power),\n",
    "                        \"mid_band\": float(np.sum(psd[low_idx:mid_idx]) / total_power),\n",
    "                        \"high_band\": float(np.sum(psd[mid_idx:]) / total_power),\n",
    "                    },\n",
    "                    \"mean_selectivity\": float(np.max(psd) / (np.mean(psd) + 1e-10)),\n",
    "                    \"spectral_entropy\": float(entropy(psd / total_power)),\n",
    "                    \"peak_frequency\": float(freq_scale[np.argmax(psd)]),\n",
    "                }\n",
    "\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"Error processing head {head_idx}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        return spectral_results\n",
    "\n",
    "    def analyze_cross_head_interference(self, attention_patterns: torch.Tensor) -> Dict:\n",
    "        \"\"\"Analyze interference between attention heads.\"\"\"\n",
    "        interference_results = {}\n",
    "        patterns = attention_patterns.cpu().numpy()\n",
    "\n",
    "        if len(patterns.shape) != 3:\n",
    "            return {}\n",
    "\n",
    "        num_heads, seq_len, _ = patterns.shape\n",
    "        window = signal.windows.hann(seq_len)\n",
    "\n",
    "        # Properly reshape window for broadcasting\n",
    "        window = window.reshape(1, -1) \n",
    "        # Average patterns and apply window\n",
    "        head_patterns = patterns.mean(axis=2)  # Shape: (num_heads, seq_len)\n",
    "        head_patterns = head_patterns * window \n",
    "\n",
    "        for i in range(num_heads):\n",
    "            for j in range(i + 1, num_heads):\n",
    "                try:\n",
    "                    n_fft = 2 ** np.ceil(np.log2(seq_len)).astype(int)\n",
    "                    fft_i = fft(head_patterns[i], n=n_fft)[: n_fft // 2]\n",
    "                    fft_j = fft(head_patterns[j], n=n_fft)[: n_fft // 2]\n",
    "\n",
    "                    psd_i = np.abs(fft_i) ** 2\n",
    "                    psd_j = np.abs(fft_j) ** 2\n",
    "                    csd = fft_i * np.conj(fft_j)\n",
    "\n",
    "                    coherence = np.abs(csd) / np.sqrt((psd_i * psd_j) + 1e-10)\n",
    "\n",
    "                    interference_results[f\"heads_{i}_{j}\"] = {\n",
    "                        \"mean_coherence\": float(np.mean(coherence)),\n",
    "                        \"peak_coherence\": float(np.max(coherence)),\n",
    "                        \"interference_strength\": float(np.mean(np.abs(csd))),\n",
    "                    }\n",
    "\n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"Error processing head pair {i},{j}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "        return interference_results\n",
    "\n",
    "    def analyze_dataset(self, num_samples: int = 500) -> Dict:\n",
    "        \"\"\"Analyze multiple samples with batch processing across all layers.\"\"\"\n",
    "        self.logger.info(f\"Starting analysis of {num_samples} samples...\")\n",
    "        dataset = load_dataset(\"bookcorpus\", split=\"train\", streaming=True)\n",
    "\n",
    "        layer_spectral_results = [[] for _ in range(self.num_layers)]\n",
    "        layer_interference_results = [[] for _ in range(self.num_layers)]\n",
    "\n",
    "        successful_samples = 0\n",
    "        batch_size = 5 \n",
    "        texts = []\n",
    "        with tqdm(desc=\"Collecting samples\", total=num_samples) as pbar:\n",
    "            for item in dataset:\n",
    "                if 10 <= len(item[\"text\"].split()) <= 100:\n",
    "                    texts.append(item[\"text\"])\n",
    "                    pbar.update(1)\n",
    "                    if len(texts) == num_samples:\n",
    "                        break\n",
    "\n",
    "        with tqdm(total=len(texts), desc=\"Analyzing patterns\") as pbar:\n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch_texts = texts[i : i + batch_size]\n",
    "\n",
    "                try:\n",
    "                    tokens = self.tokenizer(\n",
    "                        batch_texts,\n",
    "                        padding=True,\n",
    "                        truncation=True,\n",
    "                        max_length=128,  \n",
    "                        return_tensors=\"pt\",\n",
    "                    ).to(self.device)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        outputs = self.model(**tokens, output_attentions=True)\n",
    "                        for layer_idx, layer_attn in enumerate(outputs.attentions):\n",
    "                            # layer_attn shape: [batch_size, num_heads, seq_len, seq_len]\n",
    "                            avg_layer_attn = layer_attn.mean(\n",
    "                                0\n",
    "                            )  # average over batch: [num_heads, seq_len, seq_len]\n",
    "\n",
    "                            spectral_result = self.analyze_frequency_bands(\n",
    "                                avg_layer_attn\n",
    "                            )\n",
    "                            interference_result = self.analyze_cross_head_interference(\n",
    "                                avg_layer_attn\n",
    "                            )\n",
    "\n",
    "                            if spectral_result and interference_result:\n",
    "                                layer_spectral_results[layer_idx].append(\n",
    "                                    spectral_result\n",
    "                                )\n",
    "                                layer_interference_results[layer_idx].append(\n",
    "                                    interference_result\n",
    "                                )\n",
    "                        successful_samples += 1\n",
    "\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error in batch {i//batch_size}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "                pbar.update(len(batch_texts))\n",
    "\n",
    "                if successful_samples >= num_samples // batch_size:\n",
    "                    self.logger.info(\"Reached sufficient successful samples\")\n",
    "                    break\n",
    "\n",
    "        if successful_samples == 0:\n",
    "            raise ValueError(\"No samples were successfully analyzed\")\n",
    "\n",
    "        self.logger.info(f\"Successfully analyzed {successful_samples} batches\")\n",
    "\n",
    "        results = self._aggregate_all_layers(\n",
    "            layer_spectral_results, layer_interference_results\n",
    "        )\n",
    "\n",
    "        results[\"band_separation\"] = self.band_separation_measurement(\n",
    "            results[\"spectral_metrics\"]\n",
    "        )\n",
    "\n",
    "        # per-layer spectral data in results['layer_spectral_aggregates']\n",
    "        results[\"frequency_response_evolution\"] = self.frequency_response_evolution(\n",
    "            results[\"layer_spectral_aggregates\"]\n",
    "        )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _aggregate_all_layers(\n",
    "        self,\n",
    "        layer_spectral_results: List[List[Dict]],\n",
    "        layer_interference_results: List[List[Dict]],\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Aggregate results across layers and samples.\n",
    "        it produce:\n",
    "        - 'spectral_metrics': aggregated across all layers and samples (averaged),\n",
    "        - 'interference_metrics': aggregated across all layers,\n",
    "        - 'layer_spectral_aggregates': store per-layer averaged band powers for frequency response evolution.\n",
    "        \"\"\"\n",
    "        all_spectral = []\n",
    "        for layer_data in layer_spectral_results:\n",
    "            all_spectral.extend(layer_data)\n",
    "\n",
    "        all_interference = []\n",
    "        for layer_data in layer_interference_results:\n",
    "            all_interference.extend(layer_data)\n",
    "\n",
    "        spectral_metrics = self._aggregate_spectral(all_spectral)\n",
    "        interference_metrics = self._aggregate_interference(all_interference)\n",
    "\n",
    "        layer_spectral_aggregates = []\n",
    "        for layer_data in layer_spectral_results:\n",
    "            # layer_data is a list of spectral_results (one per sample)\n",
    "            layer_agg = self._aggregate_spectral(layer_data)\n",
    "            layer_spectral_aggregates.append(layer_agg)\n",
    "\n",
    "        return {\n",
    "            \"spectral_metrics\": spectral_metrics,\n",
    "            \"interference_metrics\": interference_metrics,\n",
    "            \"layer_spectral_aggregates\": layer_spectral_aggregates,\n",
    "        }\n",
    "\n",
    "    def _aggregate_spectral(self, spectral_results: List[Dict]) -> Dict:\n",
    "        \"\"\"Aggregate spectral results across multiple samples.\"\"\"\n",
    "        aggregated_spectral = {}\n",
    "\n",
    "        # spectral_results is a list of dicts, each with 'head_{i}' keys\n",
    "        for sr in spectral_results:\n",
    "            for head_key, head_data in sr.items():\n",
    "                if head_key not in aggregated_spectral:\n",
    "                    aggregated_spectral[head_key] = {\n",
    "                        \"band_powers\": {\n",
    "                            \"low_band\": [],\n",
    "                            \"mid_band\": [],\n",
    "                            \"high_band\": [],\n",
    "                        },\n",
    "                        \"mean_selectivity\": [],\n",
    "                        \"spectral_entropy\": [],\n",
    "                    }\n",
    "                aggregated_spectral[head_key][\"band_powers\"][\"low_band\"].append(\n",
    "                    head_data[\"band_powers\"][\"low_band\"]\n",
    "                )\n",
    "                aggregated_spectral[head_key][\"band_powers\"][\"mid_band\"].append(\n",
    "                    head_data[\"band_powers\"][\"mid_band\"]\n",
    "                )\n",
    "                aggregated_spectral[head_key][\"band_powers\"][\"high_band\"].append(\n",
    "                    head_data[\"band_powers\"][\"high_band\"]\n",
    "                )\n",
    "                aggregated_spectral[head_key][\"mean_selectivity\"].append(\n",
    "                    head_data[\"mean_selectivity\"]\n",
    "                )\n",
    "                aggregated_spectral[head_key][\"spectral_entropy\"].append(\n",
    "                    head_data[\"spectral_entropy\"]\n",
    "                )\n",
    "\n",
    "        # Average over all samples\n",
    "        for head_key in aggregated_spectral:\n",
    "            aggregated_spectral[head_key] = {\n",
    "                \"band_powers\": {\n",
    "                    \"low_band\": float(\n",
    "                        np.mean(\n",
    "                            aggregated_spectral[head_key][\"band_powers\"][\"low_band\"]\n",
    "                        )\n",
    "                    ),\n",
    "                    \"mid_band\": float(\n",
    "                        np.mean(\n",
    "                            aggregated_spectral[head_key][\"band_powers\"][\"mid_band\"]\n",
    "                        )\n",
    "                    ),\n",
    "                    \"high_band\": float(\n",
    "                        np.mean(\n",
    "                            aggregated_spectral[head_key][\"band_powers\"][\"high_band\"]\n",
    "                        )\n",
    "                    ),\n",
    "                },\n",
    "                \"mean_selectivity\": float(\n",
    "                    np.mean(aggregated_spectral[head_key][\"mean_selectivity\"])\n",
    "                ),\n",
    "                \"spectral_entropy\": float(\n",
    "                    np.mean(aggregated_spectral[head_key][\"spectral_entropy\"])\n",
    "                ),\n",
    "            }\n",
    "\n",
    "        return aggregated_spectral\n",
    "\n",
    "    def _aggregate_interference(self, interference_results: List[Dict]) -> Dict:\n",
    "        \"\"\"Aggregate interference results across multiple samples.\"\"\"\n",
    "        aggregated_interference = {}\n",
    "        for ir in interference_results:\n",
    "            for key, values in ir.items():\n",
    "                if key not in aggregated_interference:\n",
    "                    aggregated_interference[key] = {k: [] for k in values.keys()}\n",
    "                for k, v in values.items():\n",
    "                    aggregated_interference[key][k].append(v)\n",
    "\n",
    "        for key in aggregated_interference:\n",
    "            aggregated_interference[key] = {\n",
    "                k: float(np.mean(v)) for k, v in aggregated_interference[key].items()\n",
    "            }\n",
    "\n",
    "        return aggregated_interference\n",
    "\n",
    "    def band_separation_measurement(self, metrics: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Compute correlation between heads' band distributions to measure band separation.\n",
    "        Lower correlation between heads would indicate better band specialization.\n",
    "        \"\"\"\n",
    "        heads = sorted(metrics.keys(), key=lambda x: int(x.split(\"_\")[1]))\n",
    "        band_vectors = []\n",
    "        for h in heads:\n",
    "            bp = metrics[h][\"band_powers\"]\n",
    "            vec = [bp[\"low_band\"], bp[\"mid_band\"], bp[\"high_band\"]]\n",
    "            band_vectors.append(vec)\n",
    "\n",
    "        band_vectors = np.array(band_vectors)\n",
    "        # Compute correlation matrix between heads\n",
    "        corr_matrix = np.corrcoef(band_vectors, rowvar=True)\n",
    "\n",
    "        # Compute average off-diagonal correlation\n",
    "        n = len(heads)\n",
    "        off_diag_sum = np.sum(corr_matrix) - np.trace(corr_matrix)\n",
    "        avg_inter_head_corr = off_diag_sum / (n * (n - 1))\n",
    "\n",
    "        return {\n",
    "            \"inter_head_band_correlation\": float(avg_inter_head_corr),\n",
    "            \"correlation_matrix\": corr_matrix.tolist(),\n",
    "        }\n",
    "\n",
    "    def frequency_response_evolution(\n",
    "        self, layer_spectral_aggregates: List[Dict]\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze how frequency band distributions evolve across layers.\n",
    "        We'll compute average band powers for each layer.\n",
    "        \"\"\"\n",
    "        layer_evolution = {\n",
    "            \"low_band_mean_per_layer\": [],\n",
    "            \"mid_band_mean_per_layer\": [],\n",
    "            \"high_band_mean_per_layer\": [],\n",
    "        }\n",
    "\n",
    "        for layer_data in layer_spectral_aggregates:\n",
    "            # layer_data is aggregated spectral metrics for that layer\n",
    "            low_vals = []\n",
    "            mid_vals = []\n",
    "            high_vals = []\n",
    "            for h_data in layer_data.values():\n",
    "                low_vals.append(h_data[\"band_powers\"][\"low_band\"])\n",
    "                mid_vals.append(h_data[\"band_powers\"][\"mid_band\"])\n",
    "                high_vals.append(h_data[\"band_powers\"][\"high_band\"])\n",
    "\n",
    "            layer_evolution[\"low_band_mean_per_layer\"].append(float(np.mean(low_vals)))\n",
    "            layer_evolution[\"mid_band_mean_per_layer\"].append(float(np.mean(mid_vals)))\n",
    "            layer_evolution[\"high_band_mean_per_layer\"].append(\n",
    "                float(np.mean(high_vals))\n",
    "            )\n",
    "\n",
    "        return layer_evolution\n",
    "\n",
    "    def visualize_results(self, results: Dict):\n",
    "        \"\"\"Create visualizations of the analysis results.\"\"\"\n",
    "        if not results or \"spectral_metrics\" not in results:\n",
    "            self.logger.error(\"No valid results to visualize\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "            fig.suptitle(\"Frequency Analysis of Attention Patterns\", fontsize=16)\n",
    "\n",
    "            if results[\"spectral_metrics\"]:\n",
    "                self._plot_band_distribution(axes[0, 0], results[\"spectral_metrics\"])\n",
    "                self._plot_head_selectivity(axes[0, 1], results[\"spectral_metrics\"])\n",
    "                self._plot_spectral_entropy(axes[0, 2], results[\"spectral_metrics\"])\n",
    "\n",
    "            if \"interference_metrics\" in results and results[\"interference_metrics\"]:\n",
    "                self._plot_interference_patterns(\n",
    "                    axes[1, 0], results[\"interference_metrics\"]\n",
    "                )\n",
    "\n",
    "            if \"band_separation\" in results:\n",
    "                self._plot_band_correlation(axes[1, 1], results[\"band_separation\"])\n",
    "\n",
    "            if \"frequency_response_evolution\" in results:\n",
    "                self._plot_frequency_evolution(\n",
    "                    axes[1, 2], results[\"frequency_response_evolution\"]\n",
    "                )\n",
    "\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            return fig\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in visualization: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _plot_band_distribution(self, ax, metrics):\n",
    "        \"\"\"Plot frequency band distribution.\"\"\"\n",
    "        heads = sorted(metrics.keys(), key=lambda x: int(x.split(\"_\")[1]))\n",
    "        x = np.arange(len(heads))\n",
    "        width = 0.25\n",
    "\n",
    "        low_band = [metrics[h][\"band_powers\"][\"low_band\"] for h in heads]\n",
    "        mid_band = [metrics[h][\"band_powers\"][\"mid_band\"] for h in heads]\n",
    "        high_band = [metrics[h][\"band_powers\"][\"high_band\"] for h in heads]\n",
    "\n",
    "        ax.bar(x - width, low_band, width, label=\"Low Frequency (0-0.25)\")\n",
    "        ax.bar(x, mid_band, width, label=\"Mid Frequency (0.25-0.75)\")\n",
    "        ax.bar(x + width, high_band, width, label=\"High Frequency (0.75-1.0)\")\n",
    "\n",
    "        ax.set_title(\"Frequency Band Distribution Across Heads\")\n",
    "        ax.set_xlabel(\"Head Index\")\n",
    "        ax.set_ylabel(\"Normalized Band Power\")\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    def _plot_head_selectivity(self, ax, metrics):\n",
    "        \"\"\"Plot head selectivity.\"\"\"\n",
    "        heads = sorted(metrics.keys(), key=lambda x: int(x.split(\"_\")[1]))\n",
    "        selectivity = [metrics[h][\"mean_selectivity\"] for h in heads]\n",
    "\n",
    "        bars = ax.bar(range(len(heads)), selectivity)\n",
    "\n",
    "        norm = plt.Normalize(min(selectivity), max(selectivity))\n",
    "        colors = plt.cm.viridis(norm(selectivity))\n",
    "        for bar, color in zip(bars, colors):\n",
    "            bar.set_color(color)\n",
    "\n",
    "        ax.set_title(\"Frequency Selectivity by Attention Head\")\n",
    "        ax.set_xlabel(\"Head Index\")\n",
    "        ax.set_ylabel(\"Selectivity Score\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        sm = plt.cm.ScalarMappable(norm=norm, cmap=plt.cm.viridis)\n",
    "        plt.colorbar(sm, ax=ax, label=\"Selectivity Level\")\n",
    "\n",
    "    def _plot_interference_patterns(self, ax, metrics):\n",
    "        \"\"\"Plot interference patterns between heads.\"\"\"\n",
    "        interference_matrix = np.zeros((self.num_heads, self.num_heads))\n",
    "\n",
    "        for key, values in metrics.items():\n",
    "            i, j = map(int, key.split(\"_\")[1:])\n",
    "            interference_matrix[i, j] = values[\"mean_coherence\"]\n",
    "            interference_matrix[j, i] = values[\"mean_coherence\"]\n",
    "\n",
    "        im = ax.imshow(interference_matrix, cmap=\"viridis\", aspect=\"auto\")\n",
    "        plt.colorbar(im, ax=ax, label=\"Coherence\")\n",
    "\n",
    "        ax.set_title(\"Cross-Head Interference Patterns\")\n",
    "        ax.set_xlabel(\"Head Index\")\n",
    "        ax.set_ylabel(\"Head Index\")\n",
    "\n",
    "        for i in range(self.num_heads):\n",
    "            for j in range(self.num_heads):\n",
    "                if i != j:\n",
    "                    text_color = \"white\" if interference_matrix[i, j] > 0.5 else \"black\"\n",
    "                    ax.text(\n",
    "                        j,\n",
    "                        i,\n",
    "                        f\"{interference_matrix[i, j]:.2f}\",\n",
    "                        ha=\"center\",\n",
    "                        va=\"center\",\n",
    "                        color=text_color,\n",
    "                        fontsize=8,\n",
    "                    )\n",
    "\n",
    "    def _plot_spectral_entropy(self, ax, metrics):\n",
    "        \"\"\"Plot the spectral entropy distribution across attention heads.\"\"\"\n",
    "        heads = sorted(metrics.keys(), key=lambda x: int(x.split(\"_\")[1]))\n",
    "        entropy_values = [metrics[h][\"spectral_entropy\"] for h in heads]\n",
    "\n",
    "        bars = ax.bar(range(len(heads)), entropy_values)\n",
    "\n",
    "        norm = plt.Normalize(min(entropy_values), max(entropy_values))\n",
    "        colors = plt.cm.viridis(norm(entropy_values))\n",
    "        for bar, color in zip(bars, colors):\n",
    "            bar.set_color(color)\n",
    "\n",
    "        ax.set_title(\"Spectral Entropy by Attention Head\")\n",
    "        ax.set_xlabel(\"Head Index\")\n",
    "        ax.set_ylabel(\"Entropy\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        sm = plt.cm.ScalarMappable(norm=norm, cmap=plt.cm.viridis)\n",
    "        plt.colorbar(sm, ax=ax, label=\"Entropy Level\")\n",
    "\n",
    "    def _plot_band_correlation(self, ax, band_sep_results: Dict):\n",
    "        \"\"\"Plot the correlation matrix of band distributions for heads.\"\"\"\n",
    "        corr_matrix = np.array(band_sep_results[\"correlation_matrix\"])\n",
    "        im = ax.imshow(corr_matrix, cmap=\"viridis\", aspect=\"auto\")\n",
    "        plt.colorbar(im, ax=ax, label=\"Correlation\")\n",
    "\n",
    "        ax.set_title(\"Inter-Head Band Correlation\")\n",
    "        ax.set_xlabel(\"Head Index\")\n",
    "        ax.set_ylabel(\"Head Index\")\n",
    "\n",
    "        n = corr_matrix.shape[0]\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j:\n",
    "                    val = corr_matrix[i, j]\n",
    "                    text_color = \"white\" if val > 0.5 else \"black\"\n",
    "                    ax.text(\n",
    "                        j,\n",
    "                        i,\n",
    "                        f\"{val:.2f}\",\n",
    "                        ha=\"center\",\n",
    "                        va=\"center\",\n",
    "                        color=text_color,\n",
    "                        fontsize=8,\n",
    "                    )\n",
    "\n",
    "    def _plot_frequency_evolution(self, ax, freq_evolution: Dict):\n",
    "        \"\"\"Plot how band powers evolve across layers.\"\"\"\n",
    "        layers = np.arange(len(freq_evolution[\"low_band_mean_per_layer\"]))\n",
    "        ax.plot(layers, freq_evolution[\"low_band_mean_per_layer\"], label=\"Low Band\")\n",
    "        ax.plot(layers, freq_evolution[\"mid_band_mean_per_layer\"], label=\"Mid Band\")\n",
    "        ax.plot(layers, freq_evolution[\"high_band_mean_per_layer\"], label=\"High Band\")\n",
    "\n",
    "        ax.set_title(\"Frequency Response Evolution Across Layers\")\n",
    "        ax.set_xlabel(\"Layer\")\n",
    "        ax.set_ylabel(\"Average Band Power\")\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function that runs the complete analysis pipeline.\n",
    "    This function handles the entire process of:\n",
    "    1. Initializing the analyzer\n",
    "    2. Processing the dataset\n",
    "    3. Generating visualizations\n",
    "    4. Saving results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Initializing Frequency Analyzer...\")\n",
    "        analyzer = FrequencyAnalyzer()\n",
    "\n",
    "        print(\"\\nStarting dataset analysis...\")\n",
    "        results = analyzer.analyze_dataset(num_samples=500)\n",
    "\n",
    "        if results and results[\"spectral_metrics\"]:\n",
    "            print(\"\\nGenerating visualizations...\")\n",
    "            fig = analyzer.visualize_results(results)\n",
    "            if fig:\n",
    "                plt.show()\n",
    "\n",
    "            print(\"\\nSaving results...\")\n",
    "            torch.save(results, \"rope_frequency_analysis_results.pt\")\n",
    "\n",
    "            print(\"\\nAnalysis Summary:\")\n",
    "            print(f\"Number of heads analyzed: {len(results['spectral_metrics'])}\")\n",
    "\n",
    "            avg_entropy = np.mean(\n",
    "                [m[\"spectral_entropy\"] for m in results[\"spectral_metrics\"].values()]\n",
    "            )\n",
    "            avg_selectivity = np.mean(\n",
    "                [m[\"mean_selectivity\"] for m in results[\"spectral_metrics\"].values()]\n",
    "            )\n",
    "\n",
    "            print(f\"Average spectral entropy: {avg_entropy:.3f}\")\n",
    "            print(f\"Average frequency selectivity: {avg_selectivity:.3f}\")\n",
    "\n",
    "            print(\n",
    "                \"\\nAnalysis complete. Results saved to 'rope_frequency_analysis_results.pt'\"\n",
    "            )\n",
    "            return results\n",
    "        else:\n",
    "            print(\"Analysis failed to produce valid results\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletAnalyzer:\n",
    "    def __init__(self, model_name: str = \"meta-llama/Llama-3.2-1B\"):\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.logger.info(f\"Using device: {self.device}\")\n",
    "\n",
    "        self.logger.info(f\"Loading model {model_name}...\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            low_cpu_mem_usage=True,\n",
    "            attn_implementation=\"eager\",\n",
    "        ).to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model.eval()\n",
    "\n",
    "        self.hidden_size = self.model.config.hidden_size\n",
    "        self.num_heads = self.model.config.num_attention_heads\n",
    "        self.head_dim = self.hidden_size // self.num_heads\n",
    "        self.num_layers = self.model.config.num_hidden_layers\n",
    "\n",
    "        self.logger.info(\n",
    "            f\"Model loaded: {self.num_layers} layers, {self.num_heads} heads\"\n",
    "        )\n",
    "\n",
    "    def analyze_dataset(self, num_samples: int = 500) -> List[Dict]:\n",
    "        \"\"\"Analyze multiple samples from the dataset with progress tracking.\"\"\"\n",
    "        self.logger.info(f\"Starting analysis of {num_samples} samples...\")\n",
    "\n",
    "        dataset = load_dataset(\"bookcorpus\", split=\"train\", streaming=True)\n",
    "        texts = []\n",
    "\n",
    "        with tqdm(desc=\"Collecting samples\") as pbar:\n",
    "            for item in dataset:\n",
    "                text = item[\"text\"]\n",
    "                if 10 <= len(text.split()) <= 100: \n",
    "                    texts.append(text)\n",
    "                    pbar.update(1)\n",
    "                    if len(texts) == num_samples:\n",
    "                        break\n",
    "\n",
    "        self.logger.info(f\"Collected {len(texts)} suitable text samples\")\n",
    "\n",
    "    def analyze_dataset(self, num_samples: int = 500) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze a dataset of multiple samples and run wavelet-like property tests.\n",
    "        it will:\n",
    "        1. Load 500 samples\n",
    "        2. For each sample, run:\n",
    "           - Scale Sensitivity Test (with wavelet analysis)\n",
    "           - Multi-Resolution Analysis (wavelet-based)\n",
    "           - Uncertainty Principle Validation (positional vs wavelet-band entropy)\n",
    "           - Frame Completeness Test (wavelet-based reconstruction)\n",
    "        3. Aggregate results.\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Starting analysis of {num_samples} samples...\")\n",
    "        dataset = load_dataset(\"bookcorpus\", split=\"train\", streaming=True)\n",
    "\n",
    "        texts = []\n",
    "        with tqdm(desc=\"Collecting samples\") as pbar:\n",
    "            for item in dataset:\n",
    "                text = item[\"text\"]\n",
    "                if 10 <= len(text.split()) <= 100:\n",
    "                    texts.append(text)\n",
    "                    pbar.update(1)\n",
    "                    if len(texts) == num_samples:\n",
    "                        break\n",
    "\n",
    "        scale_sensitivity_results = []\n",
    "        multi_resolution_results = []\n",
    "        uncertainty_results = []\n",
    "        frame_results = []\n",
    "\n",
    "        with tqdm(total=len(texts), desc=\"Analyzing samples\") as pbar:\n",
    "            for idx, text in enumerate(texts):\n",
    "                try:\n",
    "                    sc_res = self.scale_sensitivity_test(text)\n",
    "                    mr_res = self.multi_resolution_analysis(text)\n",
    "                    up_res = self.uncertainty_principle_validation(text)\n",
    "                    fc_res = self.frame_completeness_test(text)\n",
    "\n",
    "                    scale_sensitivity_results.append(sc_res)\n",
    "                    multi_resolution_results.append(mr_res)\n",
    "                    uncertainty_results.append(up_res)\n",
    "                    frame_results.append(fc_res)\n",
    "\n",
    "                    if (idx + 1) % 50 == 0:\n",
    "                        if torch.cuda.is_available():\n",
    "                            torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error processing sample {idx}: {str(e)}\")\n",
    "                    continue\n",
    "                pbar.update(1)\n",
    "\n",
    "        aggregated = {\n",
    "            \"scale_sensitivity\": self._aggregate_scale_sensitivity(\n",
    "                scale_sensitivity_results\n",
    "            ),\n",
    "            \"multi_resolution\": self._aggregate_multi_resolution(\n",
    "                multi_resolution_results\n",
    "            ),\n",
    "            \"uncertainty\": self._aggregate_uncertainty(uncertainty_results),\n",
    "            \"frame_completeness\": self._aggregate_frame(frame_results),\n",
    "        }\n",
    "\n",
    "        return aggregated\n",
    "\n",
    "    def scale_sensitivity_test(\n",
    "        self, text: str, scales: List[float] = [1.0, 0.5, 0.25]\n",
    "    ) -> Dict:\n",
    "        tokens = self.tokenizer(text, return_tensors=\"pt\").to(self.device)\n",
    "        input_ids = tokens.input_ids[0]\n",
    "\n",
    "        original_attn = self._get_avg_attention(tokens)\n",
    "        original_coefs = self._wavelet_decompose_attention(original_attn)\n",
    "\n",
    "        scale_results = {}\n",
    "        for scale in scales:\n",
    "            if scale < 1.0:\n",
    "                stride = int(1 / scale)\n",
    "                scaled_ids = input_ids[::stride]\n",
    "            else:\n",
    "                scaled_ids = input_ids\n",
    "\n",
    "            scaled_ids = scaled_ids.unsqueeze(0).to(self.device)\n",
    "            attn = self._get_avg_attention(\n",
    "                {\"input_ids\": scaled_ids, \"attention_mask\": torch.ones_like(scaled_ids)}\n",
    "            )\n",
    "            scaled_coefs = self._wavelet_decompose_attention(attn)\n",
    "\n",
    "            # Compare similarity of wavelet coefficient distributions\n",
    "            similarity = self._compare_wavelet_coefficients(\n",
    "                original_coefs, scaled_coefs\n",
    "            )\n",
    "            scale_results[f\"scale_{scale}\"] = {\n",
    "                \"wavelet_similarity_with_original\": similarity\n",
    "            }\n",
    "\n",
    "        return scale_results\n",
    "\n",
    "    def multi_resolution_analysis(\n",
    "        self, text: str, window_sizes: List[int] = [16, 32, 64]\n",
    "    ) -> Dict:\n",
    "        # Analyze how wavelet coefficients vary with different window sizes on the input\n",
    "        tokens = self.tokenizer(\n",
    "            text, return_tensors=\"pt\", truncation=True, max_length=256\n",
    "        ).to(self.device)\n",
    "        input_len = tokens.input_ids.shape[-1]\n",
    "\n",
    "        resolution_results = {}\n",
    "        for wsize in window_sizes:\n",
    "            if wsize >= input_len:\n",
    "                segments = [tokens]\n",
    "            else:\n",
    "                segments = []\n",
    "                # Slide windows\n",
    "                for start in range(0, input_len - wsize + 1, wsize):\n",
    "                    window_ids = tokens.input_ids[:, start : start + wsize]\n",
    "                    window_mask = torch.ones_like(window_ids)\n",
    "                    segments.append(\n",
    "                        {\n",
    "                            \"input_ids\": window_ids.to(self.device),\n",
    "                            \"attention_mask\": window_mask.to(self.device),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            # Aggregate wavelet band entropy across segments\n",
    "            segment_band_entropies = []\n",
    "            for seg in segments:\n",
    "                attn = self._get_avg_attention(seg)\n",
    "                coefs = self._wavelet_decompose_attention(attn)\n",
    "                # coefs is a dict of form {head_i: [cA, cD1, cD2, ...]}\n",
    "                # Compute entropy of each band distribution and average\n",
    "                band_ents = self._band_entropies(coefs)\n",
    "                segment_band_entropies.append(band_ents)\n",
    "\n",
    "            # Average over segments\n",
    "            mean_band_ent = self._average_dicts(segment_band_entropies)\n",
    "            resolution_results[f\"window_{wsize}\"] = mean_band_ent\n",
    "\n",
    "        return resolution_results\n",
    "\n",
    "    def uncertainty_principle_validation(self, text: str) -> Dict:\n",
    "        tokens = self.tokenizer(\n",
    "            text, return_tensors=\"pt\", truncation=True, max_length=128\n",
    "        ).to(self.device)\n",
    "        attn = self._get_avg_attention(tokens)\n",
    "\n",
    "        pos_entropy = self._compute_positional_entropy(attn)\n",
    "        coefs = self._wavelet_decompose_attention(attn)\n",
    "        band_ents = self._band_entropies(coefs)  # Average band entropy per head\n",
    "        # pos_entropy: dict head_idx -> val\n",
    "        # band_ents: dict head_idx -> {\"approx_entropy\": val, \"detail_entropies\": [val,...]}\n",
    "        heads = sorted(pos_entropy.keys())\n",
    "        pos_arr = []\n",
    "        spec_arr = []\n",
    "        for h in heads:\n",
    "            # sum detail bands for that head\n",
    "            detail_sum = np.sum(band_ents[h][\"detail_entropies\"])\n",
    "            pos_arr.append(pos_entropy[h])\n",
    "            spec_arr.append(detail_sum)\n",
    "\n",
    "        pos_arr = np.array(pos_arr)\n",
    "        spec_arr = np.array(spec_arr)\n",
    "        correlation = np.corrcoef(pos_arr, spec_arr)[0, 1]\n",
    "\n",
    "        return {\"pos_spec_correlation\": correlation}\n",
    "\n",
    "    def frame_completeness_test(self, text: str) -> Dict:\n",
    "        tokens = self.tokenizer(\n",
    "            text, return_tensors=\"pt\", truncation=True, max_length=128\n",
    "        ).to(self.device)\n",
    "        attn = self._get_avg_attention(tokens)\n",
    "        coefs = self._wavelet_decompose_attention(attn)\n",
    "\n",
    "        # Reconstruct for each head:\n",
    "        # coefs[h]: [cA, cD1, cD2, ...]\n",
    "        seq_len = attn.shape[-1]\n",
    "        reconstruction = torch.zeros_like(attn)\n",
    "\n",
    "        for h in range(self.num_heads):\n",
    "            # Extract average pattern over queries\n",
    "            avg_pattern = attn[h].mean(0).cpu().numpy()\n",
    "            head_coefs = coefs[f\"head_{h}\"]\n",
    "            approx = head_coefs[0]\n",
    "            details = head_coefs[1:]\n",
    "            recon_signal = pywt.waverec(\n",
    "                [approx] + details, \"db2\"\n",
    "            ) \n",
    "            if len(recon_signal) > seq_len:\n",
    "                recon_signal = recon_signal[:seq_len]\n",
    "            elif len(recon_signal) < seq_len:\n",
    "                # pad\n",
    "                pad_len = seq_len - len(recon_signal)\n",
    "                recon_signal = np.pad(recon_signal, (0, pad_len))\n",
    "\n",
    "            reconstruction[h] = torch.tensor(\n",
    "                np.tile(recon_signal, (seq_len, 1)), device=attn.device\n",
    "            )\n",
    "\n",
    "        error = (attn - reconstruction).abs().mean().item()\n",
    "        return {\"reconstruction_error\": error}\n",
    "\n",
    "    def _wavelet_decompose_attention(\n",
    "        self, attn: torch.Tensor, wavelet: str = \"db2\", level: Optional[int] = None\n",
    "    ) -> Dict[str, List[np.ndarray]]:\n",
    "        # Perform 1D wavelet decomposition on the average pattern (mean over queries)\n",
    "        # Returns a dict: head_{i} -> [cA, cD1, cD2, ...]\n",
    "        num_heads, seq_len, _ = attn.shape\n",
    "        results = {}\n",
    "        # Use mean over queries to get a single vector per head\n",
    "        for h in range(num_heads):\n",
    "            head_pattern = attn[h].mean(0).cpu().numpy()\n",
    "            # Decompose\n",
    "            max_level = pywt.dwt_max_level(seq_len, pywt.Wavelet(wavelet).dec_len)\n",
    "            if level is None or level > max_level:\n",
    "                lvl = max_level\n",
    "            else:\n",
    "                lvl = level\n",
    "            coeffs = pywt.wavedec(head_pattern, wavelet=wavelet, level=lvl)\n",
    "            # coeffs = [cA, cDn, cD(n-1), ..., cD1]\n",
    "            results[f\"head_{h}\"] = coeffs\n",
    "        return results\n",
    "\n",
    "    def _band_entropies(\n",
    "        self, coefs: Dict[str, List[np.ndarray]]\n",
    "    ) -> Dict[int, Dict[str, any]]:\n",
    "        # Return a dict: head_idx -> {\"approx_entropy\": val, \"detail_entropies\": [val,...]}\n",
    "        result = {}\n",
    "        for h_key, c_list in coefs.items():\n",
    "            h_idx = int(h_key.split(\"_\")[1])\n",
    "            approx = c_list[0]\n",
    "            details = c_list[1:]\n",
    "\n",
    "            # Normalize coefficients for entropy calculation\n",
    "            def dist_entropy(arr):\n",
    "                arr = np.abs(arr)\n",
    "                arr_sum = arr.sum()\n",
    "                if arr_sum == 0:\n",
    "                    return 0.0\n",
    "                p = arr / arr_sum\n",
    "                return float(entropy(p))\n",
    "\n",
    "            a_ent = dist_entropy(approx)\n",
    "            d_ents = [dist_entropy(d) for d in details]\n",
    "\n",
    "            result[h_idx] = {\"approx_entropy\": a_ent, \"detail_entropies\": d_ents}\n",
    "        return result\n",
    "\n",
    "    def _compare_wavelet_coefficients(\n",
    "        self, coefs1: Dict[str, List[np.ndarray]], coefs2: Dict[str, List[np.ndarray]]\n",
    "    ) -> float:\n",
    "\n",
    "        correlations = []\n",
    "        for h_key in coefs1.keys():\n",
    "            if h_key in coefs2:\n",
    "                cA1 = np.abs(coefs1[h_key][0])\n",
    "                cA2 = np.abs(coefs2[h_key][0])\n",
    "                # Pad to min length\n",
    "                min_len = min(len(cA1), len(cA2))\n",
    "                cA1 = cA1[:min_len]\n",
    "                cA2 = cA2[:min_len]\n",
    "\n",
    "                # Pearson correlation\n",
    "                if np.std(cA1) < 1e-10 or np.std(cA2) < 1e-10:\n",
    "                    corr = 0.0\n",
    "                else:\n",
    "                    corr = np.corrcoef(cA1, cA2)[0, 1]\n",
    "                correlations.append(corr)\n",
    "        if len(correlations) == 0:\n",
    "            return 0.0\n",
    "        return float(np.mean(correlations))\n",
    "\n",
    "    def _average_dicts(\n",
    "        self, dicts: List[Dict[int, Dict[str, any]]]\n",
    "    ) -> Dict[int, Dict[str, any]]:\n",
    "        all_heads = set()\n",
    "        for d in dicts:\n",
    "            all_heads.update(d.keys())\n",
    "        all_heads = sorted(all_heads)\n",
    "\n",
    "        results = {}\n",
    "        for h in all_heads:\n",
    "            approx_ents = []\n",
    "            detail_ents_list = []\n",
    "            for d in dicts:\n",
    "                if h in d:\n",
    "                    approx_ents.append(d[h][\"approx_entropy\"])\n",
    "                    detail_ents_list.append(d[h][\"detail_entropies\"])\n",
    "            min_len = min(len(x) for x in detail_ents_list)\n",
    "            detail_avg = np.mean([x[:min_len] for x in detail_ents_list], axis=0)\n",
    "            results[h] = {\n",
    "                \"approx_entropy\": float(np.mean(approx_ents)),\n",
    "                \"detail_entropies\": detail_avg.tolist(),\n",
    "            }\n",
    "        return results\n",
    "\n",
    "    def _aggregate_scale_sensitivity(self, results_list: List[Dict]) -> Dict:\n",
    "        scales = [\"scale_1.0\", \"scale_0.5\", \"scale_0.25\"]\n",
    "        aggregated = {sc: [] for sc in scales}\n",
    "\n",
    "        for res in results_list:\n",
    "            for sc in scales:\n",
    "                aggregated[sc].append(res[sc][\"wavelet_similarity_with_original\"])\n",
    "\n",
    "        final = {}\n",
    "        for sc in scales:\n",
    "            final[sc] = float(np.mean(aggregated[sc]))\n",
    "\n",
    "        return final\n",
    "\n",
    "    def _aggregate_multi_resolution(self, results_list: List[Dict]) -> Dict:\n",
    "        window_keys = results_list[0].keys()\n",
    "        aggregated = {}\n",
    "        for w in window_keys:\n",
    "            approx_vals = []\n",
    "            detail_vals = []\n",
    "            for r in results_list:\n",
    "                # r[w] is {head_idx: {\"approx_entropy\":..., \"detail_entropies\":[...]}}\n",
    "                h_approx = [r[w][h][\"approx_entropy\"] for h in r[w]]\n",
    "                approx_vals.append(np.mean(h_approx))\n",
    "            aggregated[w] = {\n",
    "                \"mean_approx_entropy_across_samples\": float(np.mean(approx_vals))\n",
    "            }\n",
    "        return aggregated\n",
    "\n",
    "    def _aggregate_uncertainty(self, results_list: List[Dict]) -> Dict:\n",
    "        correlations = [r[\"pos_spec_correlation\"] for r in results_list]\n",
    "        return {\"mean_pos_spec_correlation\": float(np.mean(correlations))}\n",
    "\n",
    "    def _aggregate_frame(self, results_list: List[Dict]) -> Dict:\n",
    "        errors = [r[\"reconstruction_error\"] for r in results_list]\n",
    "        return {\"mean_reconstruction_error\": float(np.mean(errors))}\n",
    "\n",
    "    def _get_avg_attention(self, tokens: Dict) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**tokens, output_attentions=True)\n",
    "            # Average over batch and layers\n",
    "            layer_attns = [a.mean(0) for a in outputs.attentions]\n",
    "            avg_attn = torch.stack(layer_attns, dim=0).mean(0)\n",
    "            return avg_attn\n",
    "\n",
    "    def _compute_positional_entropy(self, attn: torch.Tensor) -> Dict[int, float]:\n",
    "        num_heads, seq_len, _ = attn.shape\n",
    "        pos_entropy = {}\n",
    "        for h in range(num_heads):\n",
    "            dist = attn[h].mean(0)\n",
    "            dist = dist / (dist.sum() + 1e-10)\n",
    "            pos_entropy[h] = float(entropy(dist.cpu().numpy()))\n",
    "        return pos_entropy\n",
    "\n",
    "\n",
    "def main():\n",
    "    analyzer = WaveletAnalyzer()\n",
    "    results = analyzer.analyze_dataset(num_samples=500)\n",
    "    print(\"Aggregated Results over 500 samples:\")\n",
    "    print(results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
